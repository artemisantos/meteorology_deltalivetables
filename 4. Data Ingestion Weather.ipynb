{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd467d9-4907-4f98-97d4-a63db8d188ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc9fa52a-9aa3-421e-8c31-808ce9d09211",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Logging configuration and initialization, reduced for external libraries.\n",
    "'''\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s: %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "for lib in [\"azure\", \"urllib3\", \"py4j\"]:\n",
    "    logging.getLogger(lib).setLevel(logging.WARNING)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbedafa9-8a36-48a4-8636-9513332cdb6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Fetching access data from Databricks secret.\n",
    "'''\n",
    "\n",
    "AZURE_CONNECTION_STRING = dbutils.secrets.get(\"dev_secrets\", \"storageconnection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6048b94-db9e-4cc4-9dda-3edbec07af2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initializing the client for handling Azure Blob Storage.\n",
    "'''\n",
    "\n",
    "CONTAINER_NAME = \"data\"\n",
    "blob_service = BlobServiceClient.from_connection_string(AZURE_CONNECTION_STRING)\n",
    "container_client = blob_service.get_container_client(CONTAINER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9efb8ca-787c-413d-b8fc-b4bd283be6c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Definiton of paths and API endpoints.\n",
    "'''\n",
    "\n",
    "LOCATIONS_PATH = \"openaq-locations-data\"\n",
    "WEATHER_PATH = \"openmeteo-weather-data\"\n",
    "OPEN_METEO_URL = \"https://archive-api.open-meteo.com/v1/archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b742cd43-ed63-49eb-bf6d-79cee063d5b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def list_location_blobs():\n",
    "    '''\n",
    "    Lists all blob files for locations in Azure Blob Storage.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of BlobProperties objects corresponding to location files.\n",
    "    '''\n",
    "    blobs = list(container_client.list_blobs(name_starts_with=LOCATIONS_PATH + \"/location_\"))\n",
    "\n",
    "    if not blobs:\n",
    "        logger.warning(\"No location files found in Azure Blob Storage.\")\n",
    "        return []\n",
    "    \n",
    "    return blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fea3c6b6-0634-47e1-90cd-ababdc795f3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_all_locations():\n",
    "    '''\n",
    "    Loads data from all active location JSON files in the Azure Blob Storage.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each representing an active location.\n",
    "    '''\n",
    "    all_locs = []\n",
    "    blobs = list_location_blobs()\n",
    "\n",
    "    for blob in blobs:\n",
    "        try:\n",
    "            blob_client = container_client.get_blob_client(blob.name)\n",
    "            blob_data = blob_client.download_blob().readall().decode(\"utf-8\")\n",
    "            location_dict = json.loads(blob_data)\n",
    "\n",
    "            if location_dict.get(\"is_active\", True):\n",
    "                all_locs.append(location_dict)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading location file '{blob.name}': {e}\")\n",
    "            \n",
    "    logger.info(f\"Loaded {len(all_locs)} active locations from blob storage.\")\n",
    "    return all_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da081869-fe4e-4ccf-b87b-ed25706f436d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_weather_file_for_location(location_id):\n",
    "    '''\n",
    "    Searches Azure Blob Storage for weather files for a specific location.\n",
    "\n",
    "    Args:\n",
    "        location_id (int or str): The ID of the location.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The name of the newest weather blob file for the location, or None if no file is found.\n",
    "    '''\n",
    "    prefix = f\"{WEATHER_PATH}/weather_{location_id}_\"\n",
    "    blobs = list(container_client.list_blobs(name_starts_with=prefix))\n",
    "\n",
    "    if not blobs:\n",
    "        return None\n",
    "    \n",
    "    latest_blob = max(blobs, key=lambda b: b.last_modified)\n",
    "    return latest_blob.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f145f4-f5dd-498a-901c-3370e408348f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_weather_timestamp_for_location(location_id):\n",
    "    '''\n",
    "    Retrieves the maximum timestamp from the\n",
    "    newest weather file for the specified location.\n",
    "\n",
    "    Args:\n",
    "        location_id (int or str): The ID of the location.\n",
    "\n",
    "    Returns:\n",
    "        datetime or None: The latest datetime object found in 'hourly.time' \n",
    "        within the newest weather file, or None if no data is found.\n",
    "    '''\n",
    "    latest_file = get_latest_weather_file_for_location(location_id)\n",
    "    if not latest_file:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        blob_client = container_client.get_blob_client(latest_file)\n",
    "        blob_data = blob_client.download_blob().readall().decode(\"utf-8\")\n",
    "        weather_json = json.loads(blob_data)\n",
    "\n",
    "        if (\"hourly\" not in weather_json) or (\"time\" not in weather_json[\"hourly\"]):\n",
    "            return None\n",
    "\n",
    "        times = weather_json[\"hourly\"][\"time\"]\n",
    "        if not times:\n",
    "            return None\n",
    "\n",
    "        max_dt_str = max(times)\n",
    "        max_dt = datetime.strptime(max_dt_str, \"%Y-%m-%dT%H:%M\")\n",
    "        return max_dt\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting timestamp from file '{latest_file}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a7c31b-d113-435f-a284-049696184e5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_weather_data(latitude, longitude, location_id, start_datetime):\n",
    "    '''\n",
    "    Fetches weather data from the Open-Meteo Archive API for a specific \n",
    "    latitude/longitude range from start_datetime until the latest full day (UTC). \n",
    "    Also attaches 'location_id' to the returned JSON.\n",
    "\n",
    "    Args:\n",
    "        latitude (float): The latitude of the location.\n",
    "        longitude (float): The longitude of the location.\n",
    "        location_id (int or str): The ID of the location.\n",
    "        start_datetime (datetime): The starting timestamp for the weather data query.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: A JSON-like dictionary with the weather data, or None if retrieval fails.\n",
    "    '''\n",
    "    retry_attempts = 3\n",
    "    attempt = 0\n",
    "\n",
    "    start_datetime = start_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    start_date_str = start_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    end_date = datetime.utcnow().replace(minute=0, second=0, microsecond=0)\n",
    "    end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    if start_date_str > end_date_str:\n",
    "            logger.error(f\"Skipping location {loc_id} - start_date ({start_date}) > end_date ({end_date})\")\n",
    "            exit\n",
    "            \n",
    "    while attempt < retry_attempts:\n",
    "        try:\n",
    "            params = {\n",
    "                \"latitude\": latitude,\n",
    "                \"longitude\": longitude,\n",
    "                \"start_date\": start_date_str,\n",
    "                \"end_date\": end_date_str,\n",
    "                \"timezone\": \"auto\",\n",
    "                \"hourly\": [\n",
    "                    \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"apparent_temperature\", \"pressure_msl\",\n",
    "                    \"surface_pressure\", \"precipitation\", \"rain\", \"snowfall\", \"cloud_cover\", \"cloud_cover_low\",\n",
    "                    \"cloud_cover_mid\", \"cloud_cover_high\", \"shortwave_radiation\", \"direct_radiation\",\n",
    "                    \"direct_normal_irradiance\", \"diffuse_radiation\", \"global_tilted_irradiance\",\n",
    "                    \"sunshine_duration\", \"wind_speed_10m\", \"wind_speed_100m\", \"wind_direction_10m\",\n",
    "                    \"wind_direction_100m\", \"wind_gusts_10m\", \"et0_fao_evapotranspiration\", \"weather_code\",\n",
    "                    \"snow_depth\", \"vapour_pressure_deficit\", \"soil_temperature_0_to_7cm\", \"soil_temperature_7_to_28cm\",\n",
    "                    \"soil_temperature_28_to_100cm\", \"soil_temperature_100_to_255cm\", \"soil_moisture_0_to_7cm\",\n",
    "                    \"soil_moisture_7_to_28cm\", \"soil_moisture_28_to_100cm\", \"soil_moisture_100_to_255cm\"\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            response = requests.get(OPEN_METEO_URL, params=params, timeout=200)\n",
    "\n",
    "            if response.status_code == 429:\n",
    "                logger.warning(\"API rate limit exceeded. Retrying in 60 seconds.\")\n",
    "                time.sleep(60)\n",
    "                attempt += 1\n",
    "                continue\n",
    "\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            data[\"location_id\"] = location_id\n",
    "            return data\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Error fetching weather data for location {location_id}: {e}\")\n",
    "            attempt += 1\n",
    "            time.sleep(5)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a734d90-a9f8-40dc-9b7d-6c70ef72e765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_weather_for_location(weather_dict):\n",
    "    '''\n",
    "    Saves the weather data for a specific location to a distinct JSON file,\n",
    "    but only includes timestamps up to the current hour.\n",
    "\n",
    "    Args:\n",
    "        weather_dict (dict): The weather data dictionary to be saved.\n",
    "                             Must contain 'location_id'.\n",
    "    '''\n",
    "    if not weather_dict:\n",
    "        logger.warning(\"No weather data to save.\")\n",
    "        return\n",
    "\n",
    "    # Get the current UTC time up to the hour.\n",
    "    current_utc_time = datetime.utcnow().replace(minute=0, second=0, microsecond=0)\n",
    "    \n",
    "    # Filter out future timestamps.\n",
    "    if \"hourly\" in weather_dict and \"time\" in weather_dict[\"hourly\"]:\n",
    "        valid_indices = [i for i, t in enumerate(weather_dict[\"hourly\"][\"time\"]) if datetime.strptime(t, \"%Y-%m-%dT%H:%M\") <= current_utc_time]\n",
    "        \n",
    "        # Keep only the valid timestamps and corresponding data.\n",
    "        weather_dict[\"hourly\"][\"time\"] = [weather_dict[\"hourly\"][\"time\"][i] for i in valid_indices]\n",
    "        for key in weather_dict[\"hourly\"]:\n",
    "            if key != \"time\":\n",
    "                weather_dict[\"hourly\"][key] = [weather_dict[\"hourly\"][key][i] for i in valid_indices]\n",
    "    \n",
    "    location_id = weather_dict.get(\"location_id\", \"unknown\")\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    blob_name = f\"{WEATHER_PATH}/weather_{location_id}_{timestamp}.json\"\n",
    "    \n",
    "    try:\n",
    "        blob_content = json.dumps(weather_dict, indent=2)\n",
    "        container_client.upload_blob(blob_name, blob_content, overwrite=True)\n",
    "        logger.debug(f\"Weather data saved to: {blob_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving weather data for location {location_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28588d17-a15f-4851-91b3-9bfc695e2054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    logger.info(\"Starting weather data processing for all active locations.\")\n",
    "\n",
    "    locations = load_all_locations()\n",
    "    if not locations:\n",
    "        logger.warning(\"No active locations found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    processed_count = 0\n",
    "    for loc in locations:\n",
    "        loc_id = loc.get(\"id\")\n",
    "        lat = loc.get(\"coordinates\", {}).get(\"latitude\")\n",
    "        lon = loc.get(\"coordinates\", {}).get(\"longitude\")\n",
    "\n",
    "        if not lat or not lon:\n",
    "            logger.warning(f\"Skipping location {loc_id}, missing coordinates.\")\n",
    "            continue\n",
    "\n",
    "        latest_weather_dt = get_latest_weather_timestamp_for_location(loc_id)\n",
    "        if latest_weather_dt:\n",
    "            start_datetime = latest_weather_dt + timedelta(hours=1)\n",
    "        else:\n",
    "            start_datetime = datetime.strptime(\"2025-01-01\", \"%Y-%m-%d\")\n",
    "\n",
    "        weather_data = fetch_weather_data(lat, lon, loc_id, start_datetime)\n",
    "        if (\n",
    "            weather_data \n",
    "            and \"hourly\" in weather_data \n",
    "            and \"time\" in weather_data[\"hourly\"] \n",
    "            and weather_data[\"hourly\"][\"time\"]\n",
    "        ):\n",
    "            save_weather_for_location(weather_data)\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            logger.info(f\"No new weather data for location {loc_id} (start: {start_datetime}).\")\n",
    "\n",
    "    logger.info(f\"Weather data saved for {processed_count} locations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65c12c1d-166e-439c-8192-d2cbec4b7955",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1260247856502577,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "4. Data Ingestion: Weather",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}